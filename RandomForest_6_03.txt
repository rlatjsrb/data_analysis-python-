데이터 클렌징 - 데이터에서 유의미한 내용들만 골라내기
- 데이터 클렌징은 데이터에 존재하는 이상치나 결측치를 제거해서 데이터를 정리하는 것
- 불필요한 부분을 청소해내는 과정

Feature Engineering
- Feature Engineering은 도메인 지식이나 분석을 통해서 유의미한 특징들만을 선별해내거나 Feature의 형태를 더욱 적합한 형태로 변경하는 것읕 뜻함
- 적절한 Feature Engineering은  머신러닝 모델의 성능에 큰 영향을 끼침

결정 트리(Decision Tree)
- 결정 트리 학습법은 데이터 마이닝에서 일반적으로 사용되는 방법론으로, 몇몇 입력 변수를 바탕으로 목표 변수의 값을 예측하는 모델을 생성하는 것을 목표로 함
- 잎 노드는 각 입력 변수들이 루트 노드로부터 잎 노드로 이어지는 경로에 해당되는 값들을 가질 때의 목표 변수 값에 해당

랜덤 포레스트(Random Forest)
- 랜덤 포레스트는 분류, 회귀 분석 등에 사용되는 앙상블 학습 방법의 일종
- 훈련 과정에서 구성한 다수의 결정 트리로부터 부류(분류) 또는 평균 예측치(회귀 분석)를 출력함으로써 동작
- 랜덤 포레스트는 전체 데이터의 일부를 샘플링한 서브 데이터를 이용해서 학습시킨 여러 개의 결정트리의 예측값들간에 보팅을 통해서 최종 출력값을 만들어내는 기법

앙상블 러닝(Ensemble Learning)
- 앙상블 러닝은 여러 개의 분류기의 예측 결괏값 간의 투표를 통해서 최종 결괏값을 만들어내는 기법
- 앙상블 러닝을 이용할 경우, 더욱 좋은 예측 성능을 기대

랜덤 포레스트의 하이퍼 파라미터
- 하이퍼 파리미터란 알고리즘의 동작 과정에 영향을 미치는 중요한 값들로써 알고리즘 디자이너가 결정해줘야하는 값
1. n_estimators :  
	- 랜덤 포레스트에서 사용할 결정트리 개수를 지칭
	- 기본값은 100개
	- 많이 설정할수록 성능이 향상될 수 있지만 학습 시간이 오래걸릴 수 있음
2. max_features :  
	- 결정트리 분할 기준으로 사용할 Feature 개수
3. max_depth : 
	- 트리의 최대 깊이
	- 너무 깊어지면 오버피팅이 발생할 가능성이 있음
4. min_samples_split : 
	- 노드를 분할하기 위한 최소한의 샘플 데이터 수
	- 너무 작은 경우 과적합이 발생할 가능성이 높아짐
	- 기본값은 2
		